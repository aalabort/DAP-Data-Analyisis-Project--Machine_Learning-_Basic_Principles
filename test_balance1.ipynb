{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_balance1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "code",
        "id": "eXXwA_Q9CAOt",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "\t\n",
        "from sklearn.utils import resample\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZpC1pJt1CCqg",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_train_data = pd.read_csv(\"train_data.csv\",header=None)\n",
        "df_train_labels = pd.read_csv(\"train_labels.csv\",header=None)\n",
        "df_test_data = pd.read_csv(\"test_data.csv\",header=None)\n",
        "\n",
        "columnsD = []\n",
        "for i in range(1,df_train_data.shape[1]+1):\n",
        "    txt = \"\"\n",
        "    if i <= 24:\n",
        "        txt = \"mean_band_\"+str(i)        \n",
        "    elif i <= 24*2:\n",
        "        txt = \"median_band_\"+str(i-24)\n",
        "    elif i <= 24*3:\n",
        "        txt = \"variance_band_\"+str(i-24*2)\n",
        "    elif i <= 24*4:\n",
        "        txt = \"kurtosis_band_\"+str(i-24*3)\n",
        "    elif i <= 24*5:\n",
        "        txt = \"skewness_band_\"+str(i-24*4)\n",
        "    elif i <= 24*6:\n",
        "        txt = \"min_band_\"+str(i-24*5)\n",
        "    elif i <= 24*7:\n",
        "        txt = \"max_band_\"+str(i-24*6)\n",
        "    elif i <= (24*7)+12:\n",
        "        txt = \"mean_pc_\"+str(i-((24*7)))\n",
        "    elif i <= (24*7)+(12*2):\n",
        "        txt = \"stan_deriv_pc_\"+str(i-((24*7)+12))\n",
        "    elif i <= (24*7)+(12*3):\n",
        "        txt = \"min_pc_\"+str(i-((24*7)+(12*2)))\n",
        "    elif i <= (24*7)+(12*4):\n",
        "        txt = \"max_pc_\"+str(i-((24*7)+(12*3)))\n",
        "    elif i <= (24*7)+(12*4)+12:\n",
        "        txt = \"mean_coef_\"+str(i-((24*7)+(12*4)))\n",
        "    elif i <= (24*7)+(12*4)+(12*2):\n",
        "        txt = \"stan_deriv_coef_\"+str(i-((24*7)+(12*4)+12))\n",
        "    elif i <= (24*7)+(12*4)+(12*3):\n",
        "        txt = \"min_coef_\"+str(i-((24*7)+(12*4)+(12*2)))\n",
        "    elif i <= (24*7)+(12*4)+(12*4):\n",
        "        txt = \"max_coef_\"+str(i-((24*7)+(12*4)+(12*3)))\n",
        "    \n",
        "        \n",
        "    columnsD.append(txt)\n",
        "    \n",
        "df_test_data.columns = columnsD\n",
        "df_train_data.columns = columnsD\n",
        "\n",
        "#In the future it can be expanded to more features\n",
        "columnsL = []\n",
        "for i in range(1,df_train_labels.shape[1]+1):\n",
        "    columnsL.append(\"Column_\"+str(i))\n",
        "df_train_labels.columns = columnsL\n",
        "\n",
        "\n",
        "df_train_labels[\"Column_1\"] = df_train_labels[\"Column_1\"].astype('category')\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mO_9Rj3rCCsz",
        "outputId": "01b05ba9-4051-45c2-ad80-55e46a7d7c9a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "cell_type": "code",
      "source": [
        "union = pd.concat([df_train_data, df_train_labels ], axis = 1)\n",
        "info = union.Column_1.value_counts()\n",
        "result = pd.DataFrame()\n",
        "print(info)\n",
        "info[10]\n",
        "for cat in range(1,11):\n",
        "  \n",
        "    data_to_res = union[union.Column_1 == cat]\n",
        "          #print(data_to_res)\n",
        "    samples = info[cat]\n",
        "    if(info[cat] < 500):\n",
        "        samples = 500\n",
        "    if(cat == 1):\n",
        "        samples = 1000\n",
        "    df = resample(data_to_res, replace=True, n_samples=samples)\n",
        "\n",
        "    result = pd.concat([result,df])\n",
        "\n",
        "\n",
        "print(result.Column_1.value_counts())\n",
        "result = result.sample(n=result.shape[0])\n",
        "\n",
        "df_train_labels = pd.DataFrame(result[\"Column_1\"])\n",
        "\n",
        "df_train_labels.columns = columnsL\n",
        "\n",
        "\n",
        "df_train_labels[\"Column_1\"] = df_train_labels[\"Column_1\"].astype('category')\n",
        "df_train_data = pd.DataFrame(result[columnsD])\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1     2178\n",
            "2      618\n",
            "3      326\n",
            "6      260\n",
            "4      253\n",
            "5      214\n",
            "8      195\n",
            "7      141\n",
            "9       92\n",
            "10      86\n",
            "Name: Column_1, dtype: int64\n",
            "1     1000\n",
            "2      618\n",
            "10     500\n",
            "9      500\n",
            "8      500\n",
            "7      500\n",
            "6      500\n",
            "5      500\n",
            "4      500\n",
            "3      500\n",
            "Name: Column_1, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "LnDhlk4OCVuA"
      },
      "cell_type": "markdown",
      "source": [
        "# Creating Training and Test Sets "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9yhNZZdUCCu0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = df_train_data.values\n",
        "y = df_train_labels.values.reshape(len(df_train_labels))\n",
        "X_test_unlabeled = df_test_data.values\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "wJmo-XsfVWe0"
      },
      "cell_type": "markdown",
      "source": [
        "# Scaling data"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "veqyMOhhCCzK",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "scaler = StandardScaler()\n",
        "scaler.fit(X)\n",
        "X= scaler.transform(X)\n",
        "X_test_unlabeled = scaler.transform(X_test_unlabeled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "gsrhL1PHWGzn"
      },
      "cell_type": "markdown",
      "source": [
        "# Grid Search of different Models"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9-WfyQUFCC1X",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "class EstimatorSelectionHelper:\n",
        "\n",
        "    def __init__(self, models, params):\n",
        "        if not set(models.keys()).issubset(set(params.keys())):\n",
        "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
        "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
        "        self.models = models\n",
        "        self.params = params\n",
        "        self.keys = models.keys()\n",
        "        self.grid_searches = {}\n",
        "\n",
        "    def fit(self, X, y, cv=3, n_jobs=6, verbose=1, scoring=None, refit=False):\n",
        "        for key in self.keys:\n",
        "            print(\"Running GridSearchCV for %s.\" % key)\n",
        "            model = self.models[key]\n",
        "            params = self.params[key]\n",
        "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
        "                              verbose=verbose, scoring=scoring, refit=refit,\n",
        "                              return_train_score=True)\n",
        "            gs.fit(X,y)\n",
        "            self.grid_searches[key] = gs    \n",
        "\n",
        "    def score_summary(self, sort_by='mean_score'):\n",
        "        def row(key, scores, params):\n",
        "            d = {\n",
        "                 'estimator': key,\n",
        "                 'min_score': min(scores),\n",
        "                 'max_score': max(scores),\n",
        "                 'mean_score': np.mean(scores),\n",
        "                 'std_score': np.std(scores),\n",
        "            }\n",
        "            return pd.Series({**params,**d})\n",
        "\n",
        "        rows = []\n",
        "        for k in self.grid_searches:\n",
        "            print(k)\n",
        "            params = self.grid_searches[k].cv_results_['params']\n",
        "            scores = []\n",
        "            for i in range(self.grid_searches[k].cv):\n",
        "                key = \"split{}_test_score\".format(i)\n",
        "                r = self.grid_searches[k].cv_results_[key]        \n",
        "                scores.append(r.reshape(len(params),1))\n",
        "\n",
        "            all_scores = np.hstack(scores)\n",
        "            for p, s in zip(params,all_scores):\n",
        "                rows.append((row(k, s, p)))\n",
        "\n",
        "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
        "\n",
        "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
        "        columns = columns + [c for c in df.columns if c not in columns]\n",
        "\n",
        "        return df[columns]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "o5RPBjLfCvfE",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn import preprocessing\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "\n",
        "\n",
        "models1 = {\n",
        "    'XGBClassifier': XGBClassifier(),\n",
        "    'RandomForestClassifier': RandomForestClassifier(),\n",
        "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
        "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
        "    'LogisticRegression' : LogisticRegression(),\n",
        "    'SVC': SVC(class_weight='balanced', probability=True)\n",
        "}\n",
        "\n",
        "params1 = {\n",
        "    'XGBClassifier': { 'n_estimators': [256], 'learning_rate': [0.2,0.8, 1.0] },\n",
        "    'RandomForestClassifier': { 'n_estimators': [256] },\n",
        "    'AdaBoostClassifier':  { 'n_estimators': [256] },\n",
        "    'GradientBoostingClassifier': { 'n_estimators': [256], 'learning_rate': [0.2,0.8, 1.0] },\n",
        "    'LogisticRegression': {'penalty': ['l2'], 'C' : [0.01,0.1,1]},\n",
        "    'SVC': {'kernel': ['linear'], 'C': [ 1, 3, 5,15]}\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ss_DvIHICy8A",
        "outputId": "54959563-8821-4067-9d2e-29f080a5112e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1076
        }
      },
      "cell_type": "code",
      "source": [
        "helper1 = EstimatorSelectionHelper(models1, params1)\n",
        "helper1.fit(X, y, scoring='accuracy', n_jobs=8)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running GridSearchCV for XGBClassifier.\n",
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n",
            "[Parallel(n_jobs=8)]: Done   4 out of   9 | elapsed: 33.4min remaining: 41.8min\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n",
            "[Parallel(n_jobs=8)]: Done   9 out of   9 | elapsed: 57.1min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running GridSearchCV for RandomForestClassifier.\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=8)]: Done   3 out of   3 | elapsed:  1.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running GridSearchCV for AdaBoostClassifier.\n",
            "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=8)]: Done   3 out of   3 | elapsed:  4.6min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running GridSearchCV for GradientBoostingClassifier.\n",
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=8)]: Done   4 out of   9 | elapsed: 37.6min remaining: 47.0min\n",
            "[Parallel(n_jobs=8)]: Done   9 out of   9 | elapsed: 40.8min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running GridSearchCV for LogisticRegression.\n",
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=8)]: Done   4 out of   9 | elapsed:   49.6s remaining:  1.0min\n",
            "[Parallel(n_jobs=8)]: Done   9 out of   9 | elapsed:  1.5min finished\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Running GridSearchCV for SVC.\n",
            "Fitting 3 folds for each of 4 candidates, totalling 12 fits\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "[Parallel(n_jobs=8)]: Done  10 out of  12 | elapsed:  6.9min remaining:  1.4min\n",
            "[Parallel(n_jobs=8)]: Done  12 out of  12 | elapsed:  7.5min finished\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "rfwpHMFoCy-E",
        "outputId": "bb4d90ad-e880-410a-fed2-612aa70b0718",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 627
        }
      },
      "cell_type": "code",
      "source": [
        "helper1.score_summary(sort_by='max_score')"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGBClassifier\n",
            "RandomForestClassifier\n",
            "AdaBoostClassifier\n",
            "GradientBoostingClassifier\n",
            "LogisticRegression\n",
            "SVC\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>estimator</th>\n",
              "      <th>min_score</th>\n",
              "      <th>mean_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>std_score</th>\n",
              "      <th>C</th>\n",
              "      <th>kernel</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>n_estimators</th>\n",
              "      <th>penalty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.860874</td>\n",
              "      <td>0.870079</td>\n",
              "      <td>0.881628</td>\n",
              "      <td>0.00863359</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.8</td>\n",
              "      <td>256</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.870469</td>\n",
              "      <td>0.875939</td>\n",
              "      <td>0.878933</td>\n",
              "      <td>0.00387361</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2</td>\n",
              "      <td>256</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.871002</td>\n",
              "      <td>0.873806</td>\n",
              "      <td>0.878415</td>\n",
              "      <td>0.00328442</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>256</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.868267</td>\n",
              "      <td>0.872028</td>\n",
              "      <td>0.878415</td>\n",
              "      <td>0.0045397</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2</td>\n",
              "      <td>256</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.865139</td>\n",
              "      <td>0.865967</td>\n",
              "      <td>0.866667</td>\n",
              "      <td>0.000630413</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>256</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.828358</td>\n",
              "      <td>0.842501</td>\n",
              "      <td>0.86181</td>\n",
              "      <td>0.0141371</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.8</td>\n",
              "      <td>256</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>SVC</td>\n",
              "      <td>0.841067</td>\n",
              "      <td>0.848887</td>\n",
              "      <td>0.854847</td>\n",
              "      <td>0.00577755</td>\n",
              "      <td>15</td>\n",
              "      <td>linear</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>SVC</td>\n",
              "      <td>0.843817</td>\n",
              "      <td>0.847465</td>\n",
              "      <td>0.854312</td>\n",
              "      <td>0.00484485</td>\n",
              "      <td>5</td>\n",
              "      <td>linear</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>SVC</td>\n",
              "      <td>0.842217</td>\n",
              "      <td>0.844792</td>\n",
              "      <td>0.849491</td>\n",
              "      <td>0.00332803</td>\n",
              "      <td>3</td>\n",
              "      <td>linear</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>SVC</td>\n",
              "      <td>0.836267</td>\n",
              "      <td>0.84087</td>\n",
              "      <td>0.84435</td>\n",
              "      <td>0.00339406</td>\n",
              "      <td>1</td>\n",
              "      <td>linear</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.813867</td>\n",
              "      <td>0.826475</td>\n",
              "      <td>0.843064</td>\n",
              "      <td>0.0122474</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>256</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.693626</td>\n",
              "      <td>0.704147</td>\n",
              "      <td>0.721215</td>\n",
              "      <td>0.0121776</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>l2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.666845</td>\n",
              "      <td>0.674427</td>\n",
              "      <td>0.685501</td>\n",
              "      <td>0.00800675</td>\n",
              "      <td>0.1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>l2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.61007</td>\n",
              "      <td>0.616402</td>\n",
              "      <td>0.620267</td>\n",
              "      <td>0.00451388</td>\n",
              "      <td>0.01</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>l2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>0.285714</td>\n",
              "      <td>0.298331</td>\n",
              "      <td>0.309333</td>\n",
              "      <td>0.00970983</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>256</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     estimator min_score mean_score max_score    std_score  \\\n",
              "1                XGBClassifier  0.860874   0.870079  0.881628   0.00863359   \n",
              "0                XGBClassifier  0.870469   0.875939  0.878933   0.00387361   \n",
              "3       RandomForestClassifier  0.871002   0.873806  0.878415   0.00328442   \n",
              "5   GradientBoostingClassifier  0.868267   0.872028  0.878415    0.0045397   \n",
              "2                XGBClassifier  0.865139   0.865967  0.866667  0.000630413   \n",
              "6   GradientBoostingClassifier  0.828358   0.842501   0.86181    0.0141371   \n",
              "14                         SVC  0.841067   0.848887  0.854847   0.00577755   \n",
              "13                         SVC  0.843817   0.847465  0.854312   0.00484485   \n",
              "12                         SVC  0.842217   0.844792  0.849491   0.00332803   \n",
              "11                         SVC  0.836267    0.84087   0.84435   0.00339406   \n",
              "7   GradientBoostingClassifier  0.813867   0.826475  0.843064    0.0122474   \n",
              "10          LogisticRegression  0.693626   0.704147  0.721215    0.0121776   \n",
              "9           LogisticRegression  0.666845   0.674427  0.685501   0.00800675   \n",
              "8           LogisticRegression   0.61007   0.616402  0.620267   0.00451388   \n",
              "4           AdaBoostClassifier  0.285714   0.298331  0.309333   0.00970983   \n",
              "\n",
              "       C  kernel learning_rate n_estimators penalty  \n",
              "1    NaN     NaN           0.8          256     NaN  \n",
              "0    NaN     NaN           0.2          256     NaN  \n",
              "3    NaN     NaN           NaN          256     NaN  \n",
              "5    NaN     NaN           0.2          256     NaN  \n",
              "2    NaN     NaN             1          256     NaN  \n",
              "6    NaN     NaN           0.8          256     NaN  \n",
              "14    15  linear           NaN          NaN     NaN  \n",
              "13     5  linear           NaN          NaN     NaN  \n",
              "12     3  linear           NaN          NaN     NaN  \n",
              "11     1  linear           NaN          NaN     NaN  \n",
              "7    NaN     NaN             1          256     NaN  \n",
              "10     1     NaN           NaN          NaN      l2  \n",
              "9    0.1     NaN           NaN          NaN      l2  \n",
              "8   0.01     NaN           NaN          NaN      l2  \n",
              "4    NaN     NaN           NaN          256     NaN  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "5tDyLq6SKNbQ"
      },
      "cell_type": "markdown",
      "source": [
        "## Stacked Classification using probabilities"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "eMTwqxm8JWYj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf1 = GradientBoostingClassifier(learning_rate=0.2, n_estimators = 256)\n",
        "clf2 = XGBClassifier(learning_rate = 0.2, n_estimators = 256)\n",
        "clf3 = RandomForestClassifier(n_estimators = 256)\n",
        "clf4 = SVC(C=15, kernel='linear',probability=True,class_weight='balanced')\n",
        "\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "sclf = VotingClassifier(estimators=[\n",
        "    ('gr', clf1), ('xgb', clf2), ('rf', clf3),('svc', clf4)],\n",
        "                         voting='soft')\n",
        "\n",
        "sclf = sclf.fit(X, y)\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "-oUPxWTgKS6i"
      },
      "cell_type": "markdown",
      "source": [
        "## Stacked Classification and GridSearch"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "-ufdRwDAwro1"
      },
      "cell_type": "markdown",
      "source": [
        "### Save best model pipeline"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ESQ87DDUIZag",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "name_best_model = 'stacked_LR_XGB_SVC'\n",
        "\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "\n",
        "X_train = X\n",
        "y_train = y\n",
        "X_test = X\n",
        "y_test = y\n",
        "\n",
        "best_model= sclf "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "POQeOEO2umn-"
      },
      "cell_type": "markdown",
      "source": [
        "## Semi-supervised learning (Pseudo Labeling)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4LuWWtWXIZYT",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_test_unlabeled = best_model.predict(X_test_unlabeled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "xgwuPEU6u6Bf"
      },
      "cell_type": "markdown",
      "source": [
        "### Concatenate training labels with test set pseudo labels"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "K_m2EWU0IZRr",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_semisupervised = np.concatenate((y, y_test_unlabeled))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "wG0n5j-TvO1q"
      },
      "cell_type": "markdown",
      "source": [
        "### Concatenate training features with test features"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0OaD4oab5lDa",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_semisupervised = np.concatenate((X, X_test_unlabeled))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "98ta4E01wCTC"
      },
      "cell_type": "markdown",
      "source": [
        "### Train the model including pseudo labels"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LwFC5NnXwLz0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "best_model_ss= best_model.fit(X_semisupervised,y_semisupervised)\n",
        "accuracy_best_model = best_model_ss.score(X_test,y_test)\n",
        "\n",
        "\n",
        "print('Cross Validation Accuracy of {} (best classifier) with SEMI-SUPERVISED LEARNING: {:.3f}'\n",
        "       .format(name_best_model,accuracy_best_model))\n",
        "\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5DtrxdVULJ24",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y, best_model.predict(X)))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}