{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_balance2.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "code",
        "id": "eXXwA_Q9CAOt",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Import libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from scipy import stats\n",
        "import seaborn as sns\n",
        "\t\n",
        "from sklearn.utils import resample\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from sklearn import preprocessing\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ZpC1pJt1CCqg",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_train_data = pd.read_csv(\"train_data.csv\",header=None)\n",
        "df_train_labels = pd.read_csv(\"train_labels.csv\",header=None)\n",
        "\n",
        "df_test_data = pd.read_csv(\"test_data.csv\",header=None)\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "msSLG07eHsms",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X, X_val, y, y_val = train_test_split(df_train_data, df_train_labels,  test_size=0.1,random_state=0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "mO_9Rj3rCCsz",
        "outputId": "bd5e37ec-2e05-447b-a26b-20ba9d461b07",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 521
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "columnsD = []\n",
        "for i in range(1,X.shape[1]+1):\n",
        "    txt = \"\"\n",
        "    if i <= 24:\n",
        "        txt = \"mean_band_\"+str(i)        \n",
        "    elif i <= 24*2:\n",
        "        txt = \"median_band_\"+str(i-24)\n",
        "    elif i <= 24*3:\n",
        "        txt = \"variance_band_\"+str(i-24*2)\n",
        "    elif i <= 24*4:\n",
        "        txt = \"kurtosis_band_\"+str(i-24*3)\n",
        "    elif i <= 24*5:\n",
        "        txt = \"skewness_band_\"+str(i-24*4)\n",
        "    elif i <= 24*6:\n",
        "        txt = \"min_band_\"+str(i-24*5)\n",
        "    elif i <= 24*7:\n",
        "        txt = \"max_band_\"+str(i-24*6)\n",
        "    elif i <= (24*7)+12:\n",
        "        txt = \"mean_pc_\"+str(i-((24*7)))\n",
        "    elif i <= (24*7)+(12*2):\n",
        "        txt = \"stan_deriv_pc_\"+str(i-((24*7)+12))\n",
        "    elif i <= (24*7)+(12*3):\n",
        "        txt = \"min_pc_\"+str(i-((24*7)+(12*2)))\n",
        "    elif i <= (24*7)+(12*4):\n",
        "        txt = \"max_pc_\"+str(i-((24*7)+(12*3)))\n",
        "    elif i <= (24*7)+(12*4)+12:\n",
        "        txt = \"mean_coef_\"+str(i-((24*7)+(12*4)))\n",
        "    elif i <= (24*7)+(12*4)+(12*2):\n",
        "        txt = \"stan_deriv_coef_\"+str(i-((24*7)+(12*4)+12))\n",
        "    elif i <= (24*7)+(12*4)+(12*3):\n",
        "        txt = \"min_coef_\"+str(i-((24*7)+(12*4)+(12*2)))\n",
        "    elif i <= (24*7)+(12*4)+(12*4):\n",
        "        txt = \"max_coef_\"+str(i-((24*7)+(12*4)+(12*3)))\n",
        "    \n",
        "        \n",
        "    columnsD.append(txt)\n",
        "    \n",
        "df_test_data.columns = columnsD\n",
        "X.columns = columnsD\n",
        "\n",
        "#In the future it can be expanded to more features\n",
        "columnsL = []\n",
        "for i in range(1,y.shape[1]+1):\n",
        "    columnsL.append(\"Column_\"+str(i))\n",
        "y.columns = columnsL\n",
        "\n",
        "\n",
        "y[\"Column_1\"] = y[\"Column_1\"].astype('category')\n",
        "\n",
        "\n",
        "union = pd.concat([X, y ], axis = 1)\n",
        "info = union.Column_1.value_counts()\n",
        "result = pd.DataFrame()\n",
        "print(info)\n",
        "info[10]\n",
        "for cat in range(1,11):\n",
        "  \n",
        "    data_to_res = union[union.Column_1 == cat]\n",
        "          #print(data_to_res)\n",
        "    samples = info[cat]\n",
        "    if(info[cat] < 500):\n",
        "        samples = 500\n",
        "\n",
        "    df = resample(data_to_res, replace=True, n_samples=samples)\n",
        "\n",
        "    result = pd.concat([result,df])\n",
        "\n",
        "\n",
        "print(result.Column_1.value_counts())\n",
        "result = result.sample(n=result.shape[0])\n",
        "#print(result[\"Column_1\"])\n",
        "y = pd.DataFrame(result[\"Column_1\"])\n",
        "\n",
        "y.columns = columnsL\n",
        "\n",
        "\n",
        "y[\"Column_1\"] = y[\"Column_1\"].astype('category')\n",
        "X = pd.DataFrame(result[columnsD])\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1     1966\n",
            "2      561\n",
            "3      299\n",
            "4      233\n",
            "6      232\n",
            "5      182\n",
            "8      165\n",
            "7      129\n",
            "9       85\n",
            "10      74\n",
            "Name: Column_1, dtype: int64\n",
            "1     1966\n",
            "2      561\n",
            "10     500\n",
            "9      500\n",
            "8      500\n",
            "7      500\n",
            "6      500\n",
            "5      500\n",
            "4      500\n",
            "3      500\n",
            "Name: Column_1, dtype: int64\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:55: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "LnDhlk4OCVuA"
      },
      "cell_type": "markdown",
      "source": [
        "# Creating Training and Test Sets "
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9yhNZZdUCCu0",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = X.values\n",
        "y = y.values.reshape(len(y))\n",
        "X_test_unlabeled = df_test_data.values\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "wJmo-XsfVWe0"
      },
      "cell_type": "markdown",
      "source": [
        "# Scaling data"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "veqyMOhhCCzK",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X)\n",
        "X= scaler.transform(X)\n",
        "X_test_unlabeled = scaler.transform(X_test_unlabeled)\n",
        "X_val= scaler.transform(X_val)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "gsrhL1PHWGzn"
      },
      "cell_type": "markdown",
      "source": [
        "# Grid Search of different Models"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "9-WfyQUFCC1X",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "class EstimatorSelectionHelper:\n",
        "\n",
        "    def __init__(self, models, params):\n",
        "        if not set(models.keys()).issubset(set(params.keys())):\n",
        "            missing_params = list(set(models.keys()) - set(params.keys()))\n",
        "            raise ValueError(\"Some estimators are missing parameters: %s\" % missing_params)\n",
        "        self.models = models\n",
        "        self.params = params\n",
        "        self.keys = models.keys()\n",
        "        self.grid_searches = {}\n",
        "\n",
        "    def fit(self, X, y, cv=3, n_jobs=6, verbose=1, scoring=None, refit=False):\n",
        "        for key in self.keys:\n",
        "            print(\"Running GridSearchCV for %s.\" % key)\n",
        "            model = self.models[key]\n",
        "            params = self.params[key]\n",
        "            gs = GridSearchCV(model, params, cv=cv, n_jobs=n_jobs,\n",
        "                              verbose=verbose, scoring=scoring, refit=refit,\n",
        "                              return_train_score=True)\n",
        "            gs.fit(X,y)\n",
        "            self.grid_searches[key] = gs    \n",
        "\n",
        "    def score_summary(self, sort_by='mean_score'):\n",
        "        def row(key, scores, params):\n",
        "            d = {\n",
        "                 'estimator': key,\n",
        "                 'min_score': min(scores),\n",
        "                 'max_score': max(scores),\n",
        "                 'mean_score': np.mean(scores),\n",
        "                 'std_score': np.std(scores),\n",
        "            }\n",
        "            return pd.Series({**params,**d})\n",
        "\n",
        "        rows = []\n",
        "        for k in self.grid_searches:\n",
        "            print(k)\n",
        "            params = self.grid_searches[k].cv_results_['params']\n",
        "            scores = []\n",
        "            for i in range(self.grid_searches[k].cv):\n",
        "                key = \"split{}_test_score\".format(i)\n",
        "                r = self.grid_searches[k].cv_results_[key]        \n",
        "                scores.append(r.reshape(len(params),1))\n",
        "\n",
        "            all_scores = np.hstack(scores)\n",
        "            for p, s in zip(params,all_scores):\n",
        "                rows.append((row(k, s, p)))\n",
        "\n",
        "        df = pd.concat(rows, axis=1).T.sort_values([sort_by], ascending=False)\n",
        "\n",
        "        columns = ['estimator', 'min_score', 'mean_score', 'max_score', 'std_score']\n",
        "        columns = columns + [c for c in df.columns if c not in columns]\n",
        "\n",
        "        return df[columns]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "o5RPBjLfCvfE",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn import preprocessing\n",
        "from sklearn.pipeline import make_pipeline\n",
        "from sklearn.metrics import log_loss\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "\n",
        "\n",
        "\n",
        "models1 = {\n",
        "    'XGBClassifier': XGBClassifier(),\n",
        "    'RandomForestClassifier': RandomForestClassifier(),\n",
        "    'AdaBoostClassifier': AdaBoostClassifier(),\n",
        "    'GradientBoostingClassifier': GradientBoostingClassifier(),\n",
        "    'LogisticRegression' : LogisticRegression(),\n",
        "    'SVC': SVC(class_weight='balanced',probability=True)\n",
        "}\n",
        "\n",
        "params1 = {\n",
        "    'XGBClassifier': { 'n_estimators': [512], 'learning_rate': [0.2,0.5,0.8] },\n",
        "    'RandomForestClassifier': { 'n_estimators': [512] },\n",
        "    'AdaBoostClassifier':  { 'n_estimators': [512] },\n",
        "    'GradientBoostingClassifier': { 'n_estimators': [256,512], 'learning_rate': [0.2,0.8, 1.0] },\n",
        "    'LogisticRegression': {'penalty': ['l2'], 'C' : [0.15,1,2,5]},\n",
        "    'SVC': {'kernel': ['linear'], 'C': [1, 5, 8]}\n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ss_DvIHICy8A",
        "outputId": "183ff846-c45f-426a-8839-40f15ad31bf2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "helper1 = EstimatorSelectionHelper(models1, params1)\n",
        "helper1.fit(X, y, scoring='accuracy', n_jobs=8)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running GridSearchCV for XGBClassifier.\n",
            "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "rfwpHMFoCy-E",
        "outputId": "53141ffa-68cd-4b03-9624-d808ec1eb33c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 717
        }
      },
      "cell_type": "code",
      "source": [
        "helper1.score_summary(sort_by='max_score')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "XGBClassifier\n",
            "RandomForestClassifier\n",
            "AdaBoostClassifier\n",
            "GradientBoostingClassifier\n",
            "LogisticRegression\n",
            "SVC\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>estimator</th>\n",
              "      <th>min_score</th>\n",
              "      <th>mean_score</th>\n",
              "      <th>max_score</th>\n",
              "      <th>std_score</th>\n",
              "      <th>C</th>\n",
              "      <th>kernel</th>\n",
              "      <th>learning_rate</th>\n",
              "      <th>n_estimators</th>\n",
              "      <th>penalty</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.892562</td>\n",
              "      <td>0.898278</td>\n",
              "      <td>0.90553</td>\n",
              "      <td>0.00540445</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2</td>\n",
              "      <td>512</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.889807</td>\n",
              "      <td>0.893526</td>\n",
              "      <td>0.899078</td>\n",
              "      <td>0.00400069</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.5</td>\n",
              "      <td>512</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>XGBClassifier</td>\n",
              "      <td>0.889399</td>\n",
              "      <td>0.892761</td>\n",
              "      <td>0.898618</td>\n",
              "      <td>0.00415638</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.8</td>\n",
              "      <td>512</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.894858</td>\n",
              "      <td>0.895358</td>\n",
              "      <td>0.895853</td>\n",
              "      <td>0.000406179</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2</td>\n",
              "      <td>512</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.890725</td>\n",
              "      <td>0.893827</td>\n",
              "      <td>0.895824</td>\n",
              "      <td>0.00222301</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.2</td>\n",
              "      <td>256</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>RandomForestClassifier</td>\n",
              "      <td>0.885216</td>\n",
              "      <td>0.889083</td>\n",
              "      <td>0.89447</td>\n",
              "      <td>0.00392792</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>512</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.852995</td>\n",
              "      <td>0.862711</td>\n",
              "      <td>0.870124</td>\n",
              "      <td>0.00717976</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.8</td>\n",
              "      <td>512</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.853456</td>\n",
              "      <td>0.862253</td>\n",
              "      <td>0.868747</td>\n",
              "      <td>0.00645122</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>0.8</td>\n",
              "      <td>256</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.783387</td>\n",
              "      <td>0.802195</td>\n",
              "      <td>0.832874</td>\n",
              "      <td>0.0218778</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>512</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>GradientBoostingClassifier</td>\n",
              "      <td>0.782928</td>\n",
              "      <td>0.801279</td>\n",
              "      <td>0.828742</td>\n",
              "      <td>0.0197824</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1</td>\n",
              "      <td>256</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>SVC</td>\n",
              "      <td>0.771889</td>\n",
              "      <td>0.777378</td>\n",
              "      <td>0.787517</td>\n",
              "      <td>0.00717769</td>\n",
              "      <td>8</td>\n",
              "      <td>linear</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>SVC</td>\n",
              "      <td>0.752984</td>\n",
              "      <td>0.757783</td>\n",
              "      <td>0.764055</td>\n",
              "      <td>0.00463815</td>\n",
              "      <td>5</td>\n",
              "      <td>linear</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>SVC</td>\n",
              "      <td>0.655188</td>\n",
              "      <td>0.666321</td>\n",
              "      <td>0.676037</td>\n",
              "      <td>0.00857016</td>\n",
              "      <td>1</td>\n",
              "      <td>linear</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.658402</td>\n",
              "      <td>0.662327</td>\n",
              "      <td>0.664984</td>\n",
              "      <td>0.00283254</td>\n",
              "      <td>5</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>l2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.628571</td>\n",
              "      <td>0.636728</td>\n",
              "      <td>0.648922</td>\n",
              "      <td>0.0087847</td>\n",
              "      <td>2</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>l2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.603687</td>\n",
              "      <td>0.615426</td>\n",
              "      <td>0.634695</td>\n",
              "      <td>0.013733</td>\n",
              "      <td>1</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>l2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>LogisticRegression</td>\n",
              "      <td>0.531221</td>\n",
              "      <td>0.544501</td>\n",
              "      <td>0.561267</td>\n",
              "      <td>0.0125113</td>\n",
              "      <td>0.15</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>l2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>AdaBoostClassifier</td>\n",
              "      <td>0.295089</td>\n",
              "      <td>0.324531</td>\n",
              "      <td>0.347926</td>\n",
              "      <td>0.0219903</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>NaN</td>\n",
              "      <td>512</td>\n",
              "      <td>NaN</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                     estimator min_score mean_score max_score    std_score  \\\n",
              "0                XGBClassifier  0.892562   0.898278   0.90553   0.00540445   \n",
              "1                XGBClassifier  0.889807   0.893526  0.899078   0.00400069   \n",
              "2                XGBClassifier  0.889399   0.892761  0.898618   0.00415638   \n",
              "6   GradientBoostingClassifier  0.894858   0.895358  0.895853  0.000406179   \n",
              "5   GradientBoostingClassifier  0.890725   0.893827  0.895824   0.00222301   \n",
              "3       RandomForestClassifier  0.885216   0.889083   0.89447   0.00392792   \n",
              "8   GradientBoostingClassifier  0.852995   0.862711  0.870124   0.00717976   \n",
              "7   GradientBoostingClassifier  0.853456   0.862253  0.868747   0.00645122   \n",
              "10  GradientBoostingClassifier  0.783387   0.802195  0.832874    0.0218778   \n",
              "9   GradientBoostingClassifier  0.782928   0.801279  0.828742    0.0197824   \n",
              "17                         SVC  0.771889   0.777378  0.787517   0.00717769   \n",
              "16                         SVC  0.752984   0.757783  0.764055   0.00463815   \n",
              "15                         SVC  0.655188   0.666321  0.676037   0.00857016   \n",
              "14          LogisticRegression  0.658402   0.662327  0.664984   0.00283254   \n",
              "13          LogisticRegression  0.628571   0.636728  0.648922    0.0087847   \n",
              "12          LogisticRegression  0.603687   0.615426  0.634695     0.013733   \n",
              "11          LogisticRegression  0.531221   0.544501  0.561267    0.0125113   \n",
              "4           AdaBoostClassifier  0.295089   0.324531  0.347926    0.0219903   \n",
              "\n",
              "       C  kernel learning_rate n_estimators penalty  \n",
              "0    NaN     NaN           0.2          512     NaN  \n",
              "1    NaN     NaN           0.5          512     NaN  \n",
              "2    NaN     NaN           0.8          512     NaN  \n",
              "6    NaN     NaN           0.2          512     NaN  \n",
              "5    NaN     NaN           0.2          256     NaN  \n",
              "3    NaN     NaN           NaN          512     NaN  \n",
              "8    NaN     NaN           0.8          512     NaN  \n",
              "7    NaN     NaN           0.8          256     NaN  \n",
              "10   NaN     NaN             1          512     NaN  \n",
              "9    NaN     NaN             1          256     NaN  \n",
              "17     8  linear           NaN          NaN     NaN  \n",
              "16     5  linear           NaN          NaN     NaN  \n",
              "15     1  linear           NaN          NaN     NaN  \n",
              "14     5     NaN           NaN          NaN      l2  \n",
              "13     2     NaN           NaN          NaN      l2  \n",
              "12     1     NaN           NaN          NaN      l2  \n",
              "11  0.15     NaN           NaN          NaN      l2  \n",
              "4    NaN     NaN           NaN          512     NaN  "
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "metadata": {
        "id": "YVtM6dCYcBVe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf1 = GradientBoostingClassifier(learning_rate=0.2, n_estimators=512)\n",
        "clf2 = XGBClassifier(learning_rate = 0.2, n_estimators = 512)\n",
        "clf3 = SVC(C=5, kernel='linear',probability=True, class_weight= 'balanced')\n",
        "lr = LogisticRegression()\n",
        "#sclf = StackingClassifier(classifiers=[clf1, clf2, clf3],\n",
        "#                          use_probas=True,\n",
        "#                          average_probas=False,\n",
        "#                          meta_classifier=lr)\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "sclf = VotingClassifier(estimators=[\n",
        "    ('lr', clf1), ('xgb', clf2), ('svc', clf3)],\n",
        "                         voting='soft')\n",
        "\n",
        "name_best_model = 'stacked_LR_XGB_SVC'\n",
        "\n",
        "best_model = sclf\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "best_model= best_model.fit(X,y)\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "OhI18-T76xIh"
      },
      "cell_type": "markdown",
      "source": [
        "# Validation (Give how good is our model with unseen data)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "JikphCdt6wrE",
        "outputId": "f92092fa-2fb2-49cb-d76f-4196ed36ba67",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        }
      },
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "sclf.score(X_val,y_val)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6704805491990846"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "RTP9-HAgCItX"
      },
      "cell_type": "markdown",
      "source": [
        "# Taking the full X and y now to train the model to fit thes semisupervised and also the final model."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "28fB8dJdB4YM",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = df_train_data.values\n",
        "y = df_train_labels.values.reshape(len(df_train_labels))\n",
        "X_test_unlabeled = df_test_data.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "F1GnucSNCF_r",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "\n",
        "scaler = MinMaxScaler()\n",
        "scaler.fit(X)\n",
        "X= scaler.transform(X)\n",
        "X_test_unlabeled = scaler.transform(X_test_unlabeled)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "POQeOEO2umn-"
      },
      "cell_type": "markdown",
      "source": [
        "## Semi-supervised learning (Pseudo Labeling)"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "4LuWWtWXIZYT",
        "outputId": "4750a92b-8f01-480d-a8b9-a6302a836617",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        }
      },
      "cell_type": "code",
      "source": [
        "y_test_unlabeled = best_model.predict(X_test_unlabeled)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
            "  if diff:\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "xgwuPEU6u6Bf"
      },
      "cell_type": "markdown",
      "source": [
        "### Concatenate training labels with test set pseudo labels"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "K_m2EWU0IZRr",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y_semisupervised = np.concatenate((y, y_test_unlabeled))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "wG0n5j-TvO1q"
      },
      "cell_type": "markdown",
      "source": [
        "### Concatenate training features with test features"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "0OaD4oab5lDa",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_semisupervised = np.concatenate((X, X_test_unlabeled))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "98ta4E01wCTC"
      },
      "cell_type": "markdown",
      "source": [
        "### Train the model including pseudo labels"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "LwFC5NnXwLz0",
        "outputId": "e4be51b0-c307-4fba-9046-8973e45b03b2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1890
        }
      },
      "cell_type": "code",
      "source": [
        "best_model_ss= best_model.fit(X_semisupervised,y_semisupervised)\n",
        "\n",
        "\n",
        "\n",
        "print('Cross Validation Accuracy of {} (best classifier) with SEMI-SUPERVISED LEARNING: {:.3f}'\n",
        "       .format(name_best_model,accuracy_best_model))\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y, best_model.predict(X)))"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-09559d7549b2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbest_model_ss\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_semisupervised\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_semisupervised\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m print('Cross Validation Accuracy of {} (best classifier) with SEMI-SUPERVISED LEARNING: {:.3f}'\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/voting_classifier.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    187\u001b[0m                 delayed(_parallel_fit_estimator)(clone(clf), X, transformed_y,\n\u001b[1;32m    188\u001b[0m                                                  sample_weight=sample_weight)\n\u001b[0;32m--> 189\u001b[0;31m                 for clf in clfs if clf is not None)\n\u001b[0m\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    191\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    777\u001b[0m             \u001b[0;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    778\u001b[0m             \u001b[0;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 779\u001b[0;31m             \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    781\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[0;34m(self, iterator)\u001b[0m\n\u001b[1;32m    623\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 625\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    626\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 588\u001b[0;31m         \u001b[0mjob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[0;34m(self, func, callback)\u001b[0m\n\u001b[1;32m    109\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m         \u001b[0;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 111\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    112\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, batch)\u001b[0m\n\u001b[1;32m    330\u001b[0m         \u001b[0;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    331\u001b[0m         \u001b[0;31m# arguments in memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 332\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    334\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/ensemble/voting_classifier.py\u001b[0m in \u001b[0;36m_parallel_fit_estimator\u001b[0;34m(estimator, X, y, sample_weight)\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         \u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/sklearn.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, eval_set, eval_metric, early_stopping_rounds, verbose, xgb_model)\u001b[0m\n\u001b[1;32m    504\u001b[0m                               \u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mearly_stopping_rounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    505\u001b[0m                               \u001b[0mevals_result\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 506\u001b[0;31m                               verbose_eval=verbose, xgb_model=None)\n\u001b[0m\u001b[1;32m    507\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    508\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mobjective\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_options\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"objective\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, maximize, early_stopping_rounds, evals_result, verbose_eval, xgb_model, callbacks, learning_rates)\u001b[0m\n\u001b[1;32m    202\u001b[0m                            \u001b[0mevals\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mevals\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m                            \u001b[0mobj\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeval\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeval\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m                            xgb_model=xgb_model, callbacks=callbacks)\n\u001b[0m\u001b[1;32m    205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/training.py\u001b[0m in \u001b[0;36m_train_internal\u001b[0;34m(params, dtrain, num_boost_round, evals, obj, feval, xgb_model, callbacks)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;31m# Skip the first update if it is a recovery step.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mversion\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mbst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_rabit_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mversion\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/xgboost/core.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(self, dtrain, iteration, fobj)\u001b[0m\n\u001b[1;32m    896\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mfobj\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m             _check_call(_LIB.XGBoosterUpdateOneIter(self.handle, ctypes.c_int(iteration),\n\u001b[0;32m--> 898\u001b[0;31m                                                     dtrain.handle))\n\u001b[0m\u001b[1;32m    899\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    900\u001b[0m             \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdtrain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "y1IlCR0ZfqkF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}